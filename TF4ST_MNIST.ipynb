{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF4ST MNIST.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Swift",
      "language": "swift",
      "name": "swift"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zaidalyafeai/Notebooks/blob/master/TF4ST_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "NuzYtyiH_jxK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import Foundation\n",
        "import TensorFlow\n",
        "import Python"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FU5Vko57dWnZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Download Data and Labels"
      ]
    },
    {
      "metadata": {
        "id": "nU-JcQQabi5O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "43deb303-d6f1-49f1-de92-f65e96614336"
      },
      "cell_type": "code",
      "source": [
        "let urllib = Python.import(\"urllib.request\")\n",
        "let fileBaseURL = \"https://raw.githubusercontent.com/tensorflow/swift-models/stable/MNIST/\"\n",
        "let files = [\"train-images-idx3-ubyte\", \"train-labels-idx1-ubyte\"]\n",
        "\n",
        "for file in files {\n",
        "  print(\"downloading ... \", file)\n",
        "  urllib.urlretrieve(fileBaseURL + file, filename: file)\n",
        "}"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading ...  train-images-idx3-ubyte\n",
            "downloading ...  train-labels-idx1-ubyte\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gF303ze8dxXv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Process Data "
      ]
    },
    {
      "metadata": {
        "id": "dthLi1e191dQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "var batchSize:Int32 = 32 \n",
        "\n",
        "/// Reads a file into an array of bytes.\n",
        "func readFile(_ path: String) -> [UInt8] {\n",
        "    let url = URL(fileURLWithPath: path)\n",
        "    let data = try! Data(contentsOf: url, options: [])\n",
        "    return [UInt8](data)\n",
        "}\n",
        "\n",
        "/// Reads MNIST images and labels from specified file paths.\n",
        "func readMNIST(imagesFile: String, labelsFile: String) -> (images: Tensor<Float>,\n",
        "                                                           labels: Tensor<Int32>) {\n",
        "    print(\"Reading data.\")\n",
        "    let images = readFile(imagesFile).dropFirst(16).map(Float.init)\n",
        "    let labels = readFile(labelsFile).dropFirst(8).map(Int32.init)\n",
        "    let rowCount = Int32(labels.count)\n",
        "    let imageHeight: Int32 = 28, imageWidth: Int32 = 28\n",
        "\n",
        "    print(\"Constructing data tensors.\")\n",
        "    return (\n",
        "        images: Tensor(shape: [rowCount, 1, imageHeight, imageWidth], scalars: images)\n",
        "            .transposed(withPermutations: [0, 2, 3, 1]) / 255, // NHWC\n",
        "        labels: Tensor(labels)\n",
        "    )\n",
        "}\n",
        "\n",
        "/// Split data into training and test\n",
        "func splitTrainTest<Scalar>(data: Tensor<Scalar>, labels: Tensor<Scalar>) -> (Tensor<Scalar>, Tensor<Scalar>, Tensor<Scalar> , Tensor<Scalar>) {\n",
        "  \n",
        "  let N = Int32(data.shape[0])\n",
        "  let split = Int32(0.8 * Float(N))\n",
        "  \n",
        "  let trainX = data[0..<split]\n",
        "  let trainY = labels[0..<split]\n",
        "  \n",
        "  let testX = data[split..<N]\n",
        "  let testY = labels[split..<N]\n",
        "  \n",
        "  return (trainX, trainY, testX, testY)\n",
        "}\n",
        "\n",
        "/// Extract a batch of certain size \n",
        "func minibatch<Scalar>(in x: Tensor<Scalar>, at index: Int32) -> Tensor<Scalar> {\n",
        "    let start = Int32(index * batchSize)\n",
        "    return x[start..<start+Int32(batchSize)]\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4J6Aq5jU936Z",
        "colab_type": "code",
        "outputId": "0f87b87e-cd30-4f6e-eb2c-fbd424261ed0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "// convert into tensors\n",
        "let (data, trainNumericLabels) = readMNIST(imagesFile: files[0], labelsFile: files[1])\n",
        "let labels = Tensor<Float>(oneHotAtIndices: trainNumericLabels, depth: 10)\n",
        "\n",
        "// split into training and testing \n",
        "let (trainX, trainY, testX, testY) = splitTrainTest(data: data, labels: labels)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading data.\n",
            "Constructing data tensors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UgBo0BC7d7bg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## CNN Model"
      ]
    },
    {
      "metadata": {
        "id": "YZ-tLhdlJvc2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "struct CNN: Layer {\n",
        "    var conv1 = Conv2D<Float>(filterShape: (3, 3, 1, 16), activation: relu) \n",
        "    var conv2 = Conv2D<Float>(filterShape: (3, 3, 16, 32), activation: relu) \n",
        " \n",
        "    var pool = MaxPool2D<Float>(poolSize: (2, 2), strides: (2, 2))\n",
        "  \n",
        "    var flatten = Flatten<Float>()\n",
        "  \n",
        "    var dense1 = Dense<Float>(inputSize: 5*5*32 , outputSize: 128, activation: tanh)\n",
        "    var dense2 = Dense<Float>(inputSize: 128 , outputSize: 10)\n",
        "\n",
        "    @differentiable\n",
        "    func applied(to input: Tensor<Float>, in context: Context) -> Tensor<Float> {\n",
        "      var x = input\n",
        "      x = conv1.applied(to: x, in: context)\n",
        "      x = pool.applied(to: x, in: context)\n",
        "      \n",
        "      x = conv2.applied(to: x, in: context)\n",
        "      x = pool.applied(to: x, in: context)\n",
        "      \n",
        "      x = flatten.applied(to: x, in: context)\n",
        "      \n",
        "      x = dense1.applied(to: x, in: context)\n",
        "      x = dense2.applied(to: x, in: context)\n",
        "      return x \n",
        "    }\n",
        "}\n",
        "\n",
        "let optimizer = SGD<CNN, Float>(learningRate: 0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PDES_rECKXTk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "func getAccuracy(y:Tensor<Float>, logits:Tensor<Float>) -> Float{\n",
        "  let yhat  = logits.argmax(squeezingAxis: 1) - y.argmax(squeezingAxis: 1)\n",
        "  return Float(yhat.makeNumpyArray().count(where: { $0 == 0})) / Float(yhat.shape[0])\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lV2RzLtMeBBH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training"
      ]
    },
    {
      "metadata": {
        "id": "hzGVi7oqJ820",
        "colab_type": "code",
        "outputId": "07e56ed6-d36a-49ca-84d0-520c975e5586",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "var model = CNN()\n",
        "\n",
        "let trainingContext = Context(learningPhase: .training)\n",
        "let inferenceContext = Context(learningPhase: .inference)\n",
        "\n",
        "let stepsInEpoch:Int32 = Int32(Float(testX.shape[0]) / Float(batchSize))\n",
        "var avgLoss:Float = 0.0\n",
        "var avgAcc :Float = 0.0\n",
        "\n",
        "for epoch in 0...4{\n",
        "  \n",
        "  //evaluate metrics\n",
        "  avgLoss = 0.0\n",
        "  avgAcc  = 0.0\n",
        "    \n",
        "  for i in 0..<stepsInEpoch {\n",
        "  \n",
        "    //get batches\n",
        "    let X = minibatch(in: trainX, at: i)\n",
        "    let y = minibatch(in: trainY, at: i)\n",
        "    \n",
        "    //calculate the loss and gradient\n",
        "    let (loss, grads) = model.valueWithGradient { model -> Tensor<Float> in\n",
        "        let logits = model.applied(to: X, in: trainingContext)\n",
        "        return softmaxCrossEntropy(logits: logits, oneHotLabels: y)\n",
        "    }\n",
        "\n",
        "    //make an optimizer step \n",
        "    optimizer.update(&model.allDifferentiableVariables, along: grads)    \n",
        "    \n",
        "    let logits = model.applied(to: X, in: inferenceContext)\n",
        "    let acc = getAccuracy(y:y, logits:logits)\n",
        "    \n",
        "    avgLoss += (Float(loss) ?? 0.0)/Float(stepsInEpoch)\n",
        "    avgAcc  += acc/Float(stepsInEpoch)\n",
        "  }\n",
        "  \n",
        "  print(String(format:\"epoch: %d, train_loss: %.2f, train_acc: %.2f\", (epoch+1), avgLoss, avgAcc))\n",
        "}"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1, train_loss: 1.48, train_acc: 0.62\n",
            "epoch: 2, train_loss: 0.42, train_acc: 0.92\n",
            "epoch: 3, train_loss: 0.30, train_acc: 0.95\n",
            "epoch: 4, train_loss: 0.24, train_acc: 0.96\n",
            "epoch: 5, train_loss: 0.20, train_acc: 0.97\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QqPujzSXeC8_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ]
    },
    {
      "metadata": {
        "id": "J56Zlfd0XLrD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "let stepsInEpoch = Int32(Float(testX.shape[0]) / Float(32))\n",
        "\n",
        "var avgAcc:Float = 0.0 \n",
        "\n",
        "for i in 0..<stepsInEpoch{\n",
        "  let X = minibatch(in: testX, at: i)\n",
        "  let y = minibatch(in: testY, at: i)\n",
        "  \n",
        "  let logits = model.applied(to: X, in: inferenceContext)\n",
        "  let acc = getAccuracy(y:y, logits:logits)\n",
        "  avgAcc += acc / Float(stepsInEpoch)\n",
        "}\n",
        "\n",
        "print(\"test_acc: \\(avgAcc)\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O5UpckxEsqNO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "License https://github.com/tensorflow/swift-models/blob/stable/LICENSE"
      ]
    }
  ]
}